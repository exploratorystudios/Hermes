# TI-84 Neural Network Word Classifier (V10.0) with PC Training Script

## Project Overview

This project consists of two main components:
1.  A TI-BASIC program (`.8xp` file, which internally displays "HERMES V10.0" as per its `Str9` variable) designed for TI-84 Plus series graphing calculators to perform word classification using a pre-trained neural network.
2.  A Python script (`python_trainer.py`) for training this neural network model on a PC. Training on a PC is essential for achieving effective classification performance due to the computational limitations of the calculator.

The system classifies 4-letter words into one of four predefined categories: DARK, NEWT, DEER, or DIRT. Its notable strength, when using PC-trained models, is a high degree of tolerance to misspellings and input variations.

**The recommended and practically sole method for using the TI-84 program effectively is to load a model trained via the Python script.** The on-calculator training module is present in the code for historical reasons but is **not recommended** due to severe limitations (e.g., cannot reliably exceed 25 epochs without variable overflow, extremely slow, and produces vastly inferior results).

## Core Functionality and Input Robustness

The neural network, when trained extensively with the provided Python script's data augmentation features, learns to recognize the fundamental patterns of the target words. This results in a classification system with significant robustness against input errors:

* **High Tolerance to Typos:** The PC-trained model can often correctly classify words despite multiple incorrect letters.
* **Anagram / Scrambled Letter Recognition:** Due to training on scrambled word variations, the model can frequently identify the correct category even if the letter order is mixed up (e.g., "KRDA" for "DARK").
* **"Adjacent Key" Error Resilience:** While the system is not explicitly trained with a QWERTY keyboard model, the aggressive numerical noise and character variations introduced during PC-based data augmentation allow it to often correctly classify inputs where letters have been substituted by physically adjacent keys (simulating "fat-finger" errors). The network learns to associate a wider range of noisy input patterns with the correct categories.
* **General Input Noise Immunity:** The model becomes resilient to various forms of input deviation from the exact target spellings.

**The degree of this input robustness is directly correlated with the comprehensiveness of the training performed by the Python script (particularly the number of epochs and the effectiveness of data augmentation).**

## Features

### TI-84 Program (Displays "HERMES V10.0")

* **Word Classification (Using PC-Trained Models):** Classifies user-inputted 4-letter words into one of four categories, displaying the result and a confidence score. This is most effective when using models loaded from PC training.
* **Primary Operational Flow (`CONTINUE` -> `LOAD PRETRAIN`):** The main menu is streamlined. Users select `CONTINUE` to access the classifier menu, where `LOAD PRETRAIN` should be used to load a model generated by the Python script.
* **Model Loading (`LOAD PRETRAIN`):** Loads weights and biases from the program's data section. This section is intended to be populated with data from the Python training script. A default model is included.
* **User Interface:** Menu-driven interface for navigation and operation.
* **Neural Network Implementation:**
    * Architecture: 4-input, 16-hidden, 4-output feedforward neural network.
    * Activation Function: Sigmoid, with output clamping for numerical stability.
* **Vestigial On-Calculator Training Module (STRONGLY DISCOURAGED):**
    * The TI-BASIC code includes a module for on-calculator training (accessible via `Lbl T` if manually navigated to, but not from the main menu).
    * **This module should NOT be used.** It is extremely slow, cannot reliably train beyond 25 epochs due to potential variable overflows, and the resulting model quality is exceptionally poor compared to PC-trained models. It exists purely for legacy/posterity reasons.

### Python Training Script (`python_trainer.py`)

* **Effective Model Training:** Trains the 4-16-4 neural network architecture on a PC, allowing for extensive and computationally intensive training.
* **Configurable Hyperparameters:** Allows command-line configuration of learning rate and the number of training epochs.
* **TI-BASIC Code Generation:** Outputs the trained model's weights and biases as a block of TI-BASIC code, formatted for direct insertion into the TI-84 program.
* **Advanced Data Augmentation:**
    * Implements significant data augmentation techniques, including random numerical noise applied to character encodings and aggressive scrambling of word letters.
    * These techniques are critical for developing the model's high tolerance to misspellings and input variations.
* **Model Accuracy Testing:** Includes a `test_accuracy` method to evaluate the performance of the trained model on a predefined test set.
* **File Output:** Saves the generated TI-BASIC code to a specified text file.

## Rationale for PC-Based Training

Training neural networks effectively is computationally demanding. The TI-84 calculator's processing capabilities, memory, and execution speed are insufficient for the extensive training required to achieve high accuracy and robustness. The on-board training module suffers from:
1.  **Extreme Slowness:** Training for a meaningful number of epochs would take an impractical amount of time.
2.  **Epoch Limitation:** Risk of variable overflow limits training to approximately 25 epochs, which is inadequate.
3.  **Inferior Model Quality:** Consequently, any model trained on-calculator will perform poorly.

The Python script overcomes these limitations, enabling the creation of highly effective and robust models.

## System Requirements

### TI-84 Program:

* **Calculator:** TI-84 Plus CE, TI-84 Plus C Silver Edition, or a compatible model from the TI-84 Plus series.
* **Transfer Software:** TI Connect™ CE software or a compatible alternative (e.g., TiLP) for transferring the `.8xp` program file.
* **Calculator Memory:** Sufficient free RAM.

### Python Training Script:

* **Python Version:** Python 3.x.
* **Libraries:** NumPy (`pip install numpy`).

## Setup and Installation

### TI-84 Program:

1.  **Download:** Obtain the TI-BASIC program file (e.g., `HERMESV10.8xp` or `NNCLASSIFIER_V10.8xp`).
2.  **Transfer:** Use TI Connect™ CE or similar software to send the `.8xp` file to the calculator.

### Python Training Script:

1.  **Download:** Obtain the `python_trainer.py` script file.
2.  **Install Python 3:** If not already installed, download from [python.org](https://www.python.org/).
3.  **Install NumPy:** Open a terminal or command prompt and run:
    ```bash
    pip install numpy
    ```

## Usage Instructions

### TI-84 Program (Displays "HERMES V10.0")

1.  **Execution:** Press `[prgm]`, select the program, and press `[enter]`.
2.  **Main Menu:**
    * `CONTINUE`: **Select this option.** It proceeds to the classifier menu.
    * `EXIT`: Exits the program.
3.  **Classifier Menu (after selecting `CONTINUE`):**
    * `LOAD PRETRAIN`: **This should be your first action in this menu.** It loads the weights and biases for the neural network. Use this to load models trained with the Python script.
    * `CLASSIFY`: After a model is loaded, select this to input a 4-letter word. The program will display the predicted category and a confidence percentage. Test its robustness with misspelled inputs.
    * `ABOUT`: Displays program information (shows "HERMES V10.0", version, and architecture details).
    * `EXIT`: Exits to the calculator's home screen.
    **(Note: The on-calculator training option is intentionally omitted from the main menu flow as it is not recommended.)**

### Python Training Script (`python_trainer.py`)

1.  **Execution Environment:** Open a terminal or command prompt.
2.  **Navigate:** Change to the directory containing `python_trainer.py`.
3.  **Run Script:**
    ```bash
    python python_trainer.py [options]
    ```
    **Command-line Options:**
    * `--lr FLOAT`: Sets the learning rate (Default: `0.01`).
    * `--epochs INT`: Sets the number of training epochs. Higher values (e.g., 50,000+) combined with appropriate data augmentation significantly improve robustness. (Default: `20000`).
    * `--output FILENAME`: Specifies the output file for the TI-BASIC weights code (Default: `nn_weights.txt`).
    * `--test`: Runs the `test_accuracy` method on the trained model after training completion.
    * `--no-verbose`: Suppresses detailed progress output during training.
4.  **Output:** The script generates a text file containing TI-BASIC code. This code defines the trained neural network weights and biases.

## Workflow: PC Training and Calculator Deployment (Recommended Method)

1.  **Train Model on PC:**
    * Execute `python_trainer.py` with desired parameters. For optimal robustness to typos, use a high number of epochs (e.g., 50,000 or more).
    * Example: `python python_trainer.py --epochs 75000 --lr 0.005 --output nn_model_data.txt --test`
2.  **Retrieve TI-BASIC Code:** Open the text file generated by the Python script (e.g., `nn_model_data.txt`).
3.  **Edit TI-84 Program:**
    * On the TI-84 calculator, access the program editor for the classifier program.
    * Locate the section marked `Lbl P`. This section initializes and can load weights/biases.
    * Carefully delete the existing lines that assign numerical values to matrices `[I]`, `[J]`, and lists `L₄`, `L₅`.
4.  **Insert New Model Data:**
    * Manually type the TI-BASIC code from the PC-generated text file into the cleared space within `Lbl P` in the TI-84 program editor.
    * **Important:** Use the calculator's negative sign key `[(-)]` for negative numbers (this produces `⁻`), not the subtraction key `[-]`. The Python script generates the correct `⁻` symbol.
    * This step requires precision. Using calculator connectivity software that allows code editing on a PC can simplify this.
5.  **Utilize the Updated Model:**
    * Save changes and exit the TI-84 program editor.
    * Run the program.
    * Select `CONTINUE` from the main menu.
    * **Immediately select `LOAD PRETRAIN`** from the classifier menu to activate the newly inserted PC-trained model.
    * Use `CLASSIFY` to test the model, including with misspelled inputs.

## Technical Specifications

* **Neural Network Architecture:** 4-16-4 (4 input neurons, 16 hidden layer neurons, 4 output neurons).
* **Input Encoding:** Alphabetic characters (A-Z) are converted to numerical values (1/26 through 26/26). Input words are 4 characters; shorter inputs might be implicitly padded with 0s by the encoding loop, longer inputs are truncated to 4 characters.
* **Activation Function:** Sigmoid: $f(x) = \frac{1}{(1 + e^{-x})}$. Implemented with clamping for inputs outside $\approx \pm10$ to manage numerical stability on the calculator.
* **Training Categories:** "DARK", "NEWT", "DEER", "DIRT".
* **Data Augmentation (Python Script):**
    * **Character Encoding Noise:** Random numerical values are added to the encoded representation of characters during training iterations to simulate variations.
    * **Word Scrambling:** Training examples are created by shuffling the letters of the target words.
    * These methods are crucial for the network's ability to generalize and handle noisy or misspelled input effectively.

## License

This project is licensed under the MIT License.
